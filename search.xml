<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用ROSE寻找超级增强子]]></title>
    <url>%2F2017%2F09%2F06%2F%E4%BD%BF%E7%94%A8ROSE%E5%AF%BB%E6%89%BE%E8%B6%85%E7%BA%A7%E5%A2%9E%E5%BC%BA%E5%AD%90%2F</url>
    <content type="text"><![CDATA[一、工具介绍ROSE（RANK ORDERING OF SUPER-ENHANCERS）是麻省理工学院Richard A. Young实验室开发的一种通过bam文件及gff文件寻找enhancer及其相关基因的工具，此工具由python编写。项目主页：http://younglab.wi.mit.edu/super_enhancer_code.html 二、ROSE在服务器上的安装ROSE依赖软件有：Python 2.7.3, R 2.15.3, 和 SAMtools 0.1.18，因此在安装ROSE前，首先确保服务器上安装了这三个工具。关于这三个工具的安装，可以查看这篇博文： RNA-seq分析服务器安装生信工具过程。 ROSE安装方式见以下代码： 123wget https://bitbucket.org/young_computation/rose/get/1a9bb86b5464.zipunzip 1a9bb86b5464.zip# 解压后文件见下图，可以直接通过python *.py调用工具 三、具体使用ROSE的最主要用法有ROSE_main.py和ROSE_geneMapper.py。其中ROSE_main.py 用于寻找增强子而ROSE_geneMapper.py 用于为增强子相关的基因进行注释。 ROSE_mian.py 用法1234567891011121314python ROSE_main.py -g GENOME_BUILD -i INPUT_CONSTITUENT_GFF \-r RANKING_BAM -o OUTPUT_DIRECTORY \[optional: -s STITCHING_DISTANCE -t TSS_EXCLUSION_ZONE_SIZE -c CONTROL_BAM]# 参数解释-g refseq参考基因组-i 输入gff文件，一般为使用MACS鉴定得到的Med1富集区域（gff具体格式下文介绍）-r 排序后的bam文件，同时需为bam添加index-o 输出文件目录# 可选参数-s STITCHING_DISTANCE，合并两个region的最大距离，默认值为12.5kb-t TSS_EXCLUSION_ZONE_SIZE，排除TSS区域大小，排除与TSS前后某距离内的区域，以排除启动子偏差（默认值：0;推荐值：2500）。如果设置该值为0，将不会查找基因。-c CONTROL_BAM，control样本的bam文件 输入文件格式要求： bam文件格式要求：需要排序和构建index（samtools可以操作），bam文件的染色体id需要以chr开头。 gff文件格式要求：gff文件必须有以下列1.染色体位置（chr#）2.每个增强子区域的特定id4.区域起始位置5.区域终止位置7.正负链信息（+, -, .）gff格式参考：https://genome.ucsc.edu/FAQ/FAQformat.html#format3 ROSE也有转换bam为gff的工具，在运行ROSE_mian.py 时，会调用ROSE_bamToGFF.py 。 ROSE_main.py运行实例：123python $SOFT_PATH/ROSE_main.py -g HG38 -i $WORK_PATH/gtf/KYSE510_peaks.bed \-r $WORK_PATH/samtools_sort/sort_treat1.bam -c $WORK_PATH/samtools_sort/sort_control1.bam \-o $WORK_PATH/ROSE/KYSE510 -s 12500 -t 2000 2&gt;$LOG_PATH/KYSE510_enhancer.log 其中，更多基因组可以从此处获取保存到ROSE的annotation文件夹，但是需要注意修改相应ROSE_mian.py的相应代码。 输出文件如下：1.**OUTPUT_DIRECTORY/gff/*.gtf 该文件为输入gtf文件的副本； 2.**OUTPUT_DIRECTORY/gff/*STITCHED*.gtf 该文件为通过在STITCHING_DISTANCE将INPUT_CONSTITUENT_GFF拼接在一起创建的gff文件；文件列数如下：chrom, name, [blank], start, end, [blank], [blank], strand, [blank], [blank], name其中 name 字段的命名方式为：拼接起来的区域数+最左端区域ID。 3.**OUTPUT_DIRECTORY/mappedGFF/*_MAPPED.gff 每个bam文件通过bamToGFF的输出文件，包含以下列：（成分ID，测试区域，平均读取密度（单位为每百万位元每百万映射的单位读数密度）） 4.**OUTPUT_DIRECTORY/mappedGFF/* _STITCHED * _MAPPED.gff 每个bam文件通过bamToGFF的输出文件，该文件中对增强子区域进行了拼接，包含以下列：（拼接增强子ID，测试区域，平均读取密度（单位为百万映射每单位拼接增强子数）） 5.**OUTPUT_DIRECTORY/STITCHED_ENHANCER_REGION_MAP.txt bamToGFF计算后得到的拼接增强子密度文件，包含以下列：（拼接增强子ID，染色体，拼接增强子起始位置，拼接增强子末端位置，拼接数，BAM信号等级，BAM信号） 6..**OUTPUT_DIRECTORY/*_AllEnhancers.table.txt 增强子列表，包含每个增强子的排名和是否为超级增强子，包含以下列：（增强子ID，染色体，拼接增强子起始位点，拼接增强子末端，拼接数，拼接成分大小，BAM的信号，BAM的等级，是否为超增强子：是（1）否（0）） 7.**OUTPUT_DIRECTORY/* _SuperEnhancers.table.txt 超级增强子的排名，为*_AllEnhancers.table.txt 文件的子集。包含以下列：（拼接增强剂ID，染色体，拼接增强子起始位点，拼接增强子末端，拼接数，缝合在一起的成分的大小，RANKING_BAM的信号，RANKING_BAM的等级，超增强子的二进制（1）与典型（0）） 8.**OUTPUT_DIRECTORY/*_Enhancers_withSuper.bed 可以加载到UCSC浏览器中可视化的增强子bed文件 9.**OUTPUT_DIRECTORY/*_Plot_points.png 所有增强子散点图，如下图： ROSE_geneMapper.py 用法12345678910Usage: ROSE_geneMapper.py [options] -g [GENOME] -i [INPUT_ENHANCER_FILE]# 参数解释-i INPUT 输入ROSE_mian.py生成的enhancer table文件-g GENOME 输入genome信息（MM9,MM8,HG18,HG19等） -o OUT 输出路径# 可选参数-l GENELIST 要过滤的基因列表-w WINDOW 搜索基因距离，默认值为50,000bp-f format 如果使用此参数，将保持原输入文件格式输出 ROSE_geneMapper.py 运行实例： 12python $SOFT_PATH/ROSE_geneMapper.py -i $WORK_PATH/ROSE/TE7/TE7_peaks_AllEnhancers.table.txt \-g HG38 -o $WORK_PATH/ROSE/TE7 2&gt;$LOG_PATH/TE7_enhancer_anno.log 输出文件如下：1.**OUTPUT_DIRECTORY/*ENHANCER_TO_GENE.txt enhancer重叠基因、附近基因以及最近的基因列表 2.**OUTPUT_DIRECTORY/*GENE_TO_ENHANCER.txt 以每个基因为列名的和其相关的增强子位置信息列表 得到这两个表格即可对基因进行筛选然后进行GO及KEGG分析等。 下图是运行两工具的结果截图： 其中被红框标注的部分是ROSE_geneMapper.py 运行的结果。]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[htseq-count使用说明]]></title>
    <url>%2F2017%2F08%2F12%2Fhtseq-count%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[htseq-count是一款用于reads计数的轻便软件，可以用于多种mapping软件（tophat、HISAT2、BWA等）的输出结果进行计数。 一、htseq-count参数简介1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 用法概述usage: htseq-count [options] alignment_file gff_file# -h参数可显示帮助列表 -h, --help show this help message and exit# -f参数指定输入文件格式类型，默认文件类型为sam -f &#123;sam,bam&#125;, --format &#123;sam,bam&#125;# -r参数指定文件的排序方式，pos:按照染色体位置排序，name:按照read名称进行排序。双端测序数据必选参数，默认值为name。对于单端测序数据，该选项可以忽略 -r &#123;pos,name&#125;, --order &#123;pos,name&#125; # 当-r参数设定为pos，该选项可以选择最大内存，该参数对单端测序数据无效 --max-reads-in-buffer MAX_BUFFER_SIZE# -s参数指定数据建库的链特异性情况，默认值为yes。对于双端测序数据，大多数为非链特异性建库 -s &#123;yes,no,reverse&#125;, --stranded &#123;yes,no,reverse&#125; # -a参数指定最低read mapping质量值，低于&lt;minaqual&gt;值会被过滤掉（默认值为10） -a MINAQUAL, --minaqual MINAQUAL # -t参数指定指定最小计数单位类型，（GFF文件中的第三列：如exon），当RNA-seq分析采用 Ensembl GTF 文件类型时，默认值是exon -t FEATURETYPE, --type FEATURETYPE# -i参数指定最终作为特征id的值，当分析采用Ensembl GTF文件类型是，默认值是gene_id -i IDATTR, --idattr IDATTR# --additional-attr ADDITIONAL_ATTR [ADDITIONAL_ATTR ...] Additional feature attributes (default: none, suitable for Ensembl GTF files: gene_name) # -m参数指定判断一个reads属于某个基因的模型，用来判断统计reads的时候对一些比较特殊的reads定义是否计入。&lt;mode&gt; 包括：默认的union和intersection-strict、 intersection-nonempty （默认：union） -m &#123;union,intersection-strict,intersection-nonempty&#125;, --mode &#123;union,intersection-strict,intersection-nonempty&#125; mode to handle reads overlapping more than one feature (choices: union, intersection-strict, intersection- nonempty; default: union) --nonunique &#123;none,all&#125; Whether to score reads that are not uniquely aligned or ambiguously assigned to features --secondary-alignments &#123;score,ignore&#125; Whether to score secondary alignments (0x100 flag) --supplementary-alignments &#123;score,ignore&#125; Whether to score supplementary alignments (0x800 flag) -o SAMOUTS [SAMOUTS ...], --samout SAMOUTS [SAMOUTS ...] write out all SAM alignment records into an output SAM file called SAMOUT, annotating each line with its feature assignment (as an optional field with tag 'XF') -q, --quiet suppress progress report 指定输入文件的格式，&lt;format&gt; 可以是 sam (for text SAM files) 或 bam (for binary BAM files)格式，默认是sam. 对于双端测序数据，必须要对SAM文件进行排序，对read name或 染色体位置 进行排序皆可，但是推荐使用read name进行排序，将会大大节约时间及服务器资源。通过 -r 可以指定数据是以什么方式排序的： 可以是 name 或 pos ， 默认是name.如果数据没有排序，可以通过samtools sort(推荐)或msort 排序。 二、htseq-count的输入文件输入为sam或bam格式文件，需要注意的是，如果是paired-end数据必须按照reads名称排序（sort by name），否则运行时间很长，且内存占用高。 1samtools sort -n file.bam #sort bam by name 三、htseq-count的使用和参数1Usage：htseq-count [options] &lt;sam_file&gt; &lt;gff_file&gt; 主要参数说明： -m 计数模型，统计reads的时候对一些比较特殊的reads定义是否计入。包括：默认的union和intersection-strict、 intersection-nonempty具体说明如图所示。htseq-count-s reads是否匹配到同一条链上，默认：yes，可以设置no 、 reverse。对于一般的RNA-seq数据，一般选择no-t feature type 计数单位类型，在gtf或者gff文件中，外显子为最小的定义单位，可选参数有：exon, gene, transcript。默认值：exon-i 最终的计数单位，一般为基因。 默认为：gene_id 也可以设置转录本，但由于模型问题，计数效果不佳。-o 输出所有alignment的reads到一个sam文件中。可以不设置。 四、htseq-count的结果文件结果文件如下图所示： 可以看到是两列的文件，第一列是ensemble id，第二列则是该基因的count值。文件末尾会对重复值或没有匹配上的值进行统计。 多个样本通过htseq-count得到的count文件可以通过脚本进行可并为count值矩阵，进而使用DEseq2等R包进行下游分析。]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RNA-seq数据分析实例（胶质瘤）]]></title>
    <url>%2F2017%2F08%2F10%2FRNA-seq%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E4%BE%8B%EF%BC%88%E8%83%B6%E8%B4%A8%E7%98%A4%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、下载比对参考基因组文件，为HISAT2配置index配置index需要基因组注释文件（通常为gtf格式）以及基因组序列文件（fasta格式）。多个数据库提供此注释文件，此处采用ensemble提供的文件。 12345678910# 从ensemble中下载最新版本的人类基因组注释文件（gtf格式）wget ftp://ftp.ensembl.org/pub/release-89/gtf/homo_sapiens/Homo_sapiens.GRCh38.89.gtf.gz# 下载人类基因组序列wget ftp://ftp.ensembl.org/pub/current_fasta/homo_sapiens/dna_index/Homo_sapiens.GRCh38.dna.toplevel.fa.gz#配置HISAT2的indexhisat2-build -p 8 Homo_sapiens.GRCh38.dna.toplevel.fa GRCh38_ensembl_dna 1&gt;build_index.log&amp;#配置index用时约2小时，结果文件为下图所示 二、下载sra数据进入GEO页面输入id号，进入sra study的ftp下载页面，复制sra文件的链接，在linux下执行以下命令进行下载。 1nohup wget -c [文件链接] &gt; download.log&amp; 三、将sra文件转换成fastq.gz格式每秒可生产1M文件，工具不支持多线程。1234567#对文件夹下的所有sra文件批量处理for i in *sradoecho $i# 对于双端测序数据，需要加--split-3参数，每样本处理约10minfastq-dump --split-3 $i --gzip done 每个sra文件会产生两个fastq.gz文件，名称分别为*_1.fastq.gz和*_2.fastq.gz 四、对fastq数据进行质控使用fastqc(项目主页在此)进行质量控制，代码如下： 123456for id in *fastqdoecho $id# 此处使用8线程，平均每文件处理约10min/home/RNAseq_tool/FastQC/fastqc -t 8 $id -o /data/GSE86202/0.fastqc/done 得到一个html格式报告以及包含html及表格形式报告的压缩包。其中html文件可以看出数据质量。以SRR4095543_1.fastq为例，下图是其原始序列质量，可看出测序质量较高。 但是其在5’端存在adapter，从下图可以看出。 因此需要切除5’端接头，此处选择切除10bp。 五、接头处理并再次质控使用cutadapt（项目主页）进行接头处理，代码如下：123456for id in *fastqdoecho $id# 切除序列5'前10个碱基，每个文件处理约5mincutadapt -u 10 -o /data/GSE86202/cut_$id $iddone 注意：在实际流程中，原始数据可能存在各种各样的问题，需要根据fastqc质控结果按需处理。本例中的处理方式仅对本数据有效。 再次质控结果： 可以看到每个碱基的碱基组成趋于正常。 六、序列比对本例使用HISAT2进行序列比对，其速度更快且精度更高，是Tophat的优秀替代工具。比对代码如下。 123456789101112DATA_PATH=/data/GSE86202/1.cutadaptREF_PATH=/data/reference_dataOUT_PATH=/data/GSE86202/4.hisat2FILE=/data/GSE86202/filelist.txtcd $DATA_PATHcat $FILE | while read linedohisat2 -x $REF_PATH/hisat_GRCh38 --no-mixed -1 $DATA_PATH/cut_$&#123;line&#125;_1.fastq -2 #将HISAT2处理的结果输出到samtools转化为bam格式#此处使用6核，约使用6.4G内存，平均每文件处理需30min$DATA_PATH/cut_$&#123;line&#125;_2.fastq -p 6 |samtools view -bS 1&gt;$OUT_PATH/$&#123;line&#125;.bamdone 七、对bam文件排序使用samtools（项目主页）对bam文件进行排序并添加index12345678910111213FILE_PATH=/data/GSE86202/4.hisat2OUT_PATH=/data/GSE86202/5.samtoolscd $FILE_PATHfor file in *.bamdo# 对bam文件进行排序（-n参数必须，表示按照read name进行排序） samtools sort -n $FILE_PATH/$&#123;file&#125; -o $OUT_PATH/sorted_$&#123;file&#125; -@ 6# 对已经排序的bam文件进行简单质量控制 samtools flagstat $OUT_PATH/sorted_$&#123;file&#125; -@ 6 &gt; $OUT_PATH/$&#123;file&#125;.statdone# 质控后得到结果如下图所示 可看到比对结果良好。 八、使用htseq得到count值使用RSeQC进行对bam文件的简单质控和各项参数的检查12345678910111213FILE_PATH=/data/GSE86202/5.samtools/gencode_genomeREF_PATH=/data/reference_data/gtfOUT_PATH=/data/GSE86202/10.htseq/gencode_genomecd $FILE_PATHfor i in `seq 42..47`do nohup htseq-count -t exon -s reverse \ -r name -f bam $FILE_PATH/name_new_SRR40955$&#123;i&#125;.bam \ $REF_PATH/gencode.v26.annotation.gtf \ &gt; $OUT_PATH/name_new_SRR40955$&#123;i&#125;.bam.count \ &gt; SRR40955$&#123;i&#125;_count.log 2&gt;&amp;1 &amp;done 得到count值文件数与样本数据数量相等，为两列值（如下图所示），其中包括了测序数据覆盖gene的ensemble号及count值。 写perl脚本combine_count.pl将所有count值进行合并，合并文件如下图所示： 九、使用R及count矩阵进行差异分析count矩阵数据可以直接使用R中DEseq2包进行差异分析、GO分析以及pathway分析。]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RNA-seq分析所用生信工具安装详细记录]]></title>
    <url>%2F2017%2F08%2F05%2FRNA-seq%E5%88%86%E6%9E%90%E6%89%80%E7%94%A8%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E8%AF%A6%E7%BB%86%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[一.测试服务器设定1.使登录后自动进入/home目录下123vim ~/.bashrc#在文件中加入以下行后保存退出cd /home 2.新建RNAseq_tool文件夹，存放各工具1mkdir RNAseq_tool 二.各生信工具在测试服务器下的安装1.sratoolkit下载及安装123456789101112131415161718#下载并解压wget "ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gz"tar -xzf sratoolkit.current-centos_linux64.tar.gz#进入bin目录cd [download_location]/sratoolkit[version]/bin/#设置path并使其生效vi /etc/profile增加以下行export PATH=$PATH:/home/RNAseq_tool/sratoolkit.2.8.2-ubuntu64/binvi /etc/environment增加以下行：PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/RNAseq_tool/sratoolkit.2.8.2-1-ubuntu64/bin"source /etc/profilesource /etc/enviroment#测试安装是否成功fastq-dump –version#运行案例fastq-dump -X 5 -Z SRR390728 12#配置SRAtoolkit的下载路径[安装路径]/bin/vdb-config –i 设定下载路径 2.fastqc下载及安装123456789101112131415161718192021222324252627282930#fastqc需要java环境，首先下载并配置java，此处下载 jre1.8.0_144wget http://javadl.oracle.com/webapps/download/AutoDL?BundleId=225345_090f390dda5b47b9b721c7dfaa008135#进入安装目录解压tar –xzvf jre-8u144-linux-x64.tar.gz#配置java的环境变量vi /etc/profile添加以下行JAVA_HOME=/usr/java/jre1.8.0_144/export CLASSPATH=.:$JAVA_HOME/lib:$CLASSPATHexport PATH = $PATH:$JAVA_HOME/binvi /etc/environment添加java安装目录，此时文件内容为：PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/RNAseq_tool/sratoolkit.2.8.2-1-ubuntu64/bin:/usr/java/jre1.8.0_144/bin"#下载及解压wget http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zipunzip fastqc_v0.11.5.zipcd FastQC#添加执行权限chmod 755 fastqc#建立软连接ln -s [download_location]/FastQC/fastqc /usr/local/bin/fastqc#测试fastqc是否正常运行fastqc SRR390728.fastq #运行结果如下图所示 处理好的SRR390728_fastqc.html可以通过WinSCP下载到Windows系统上进行查看。 3.cutadapt下载及安装123456#安装python-pip，python-devapt-get install python-pip python-dev#使用pip安装cutadapt，该方法将cutadapt二进制文件安装到./usr/.local/bin中,无需设置环境变量pip install --user --upgrade cutadapt#尝试运行cutadapt --version 4.fastx-toolkit下载及安装123456789101112131415161718#下载并安装依赖库libgtextutils 0.7wget https://github.com/agordon/libgtextutils/releases/download/0.7/libgtextutils-0.7.tar.gztar –xzvf libgtextutils-0.7.tar.gz#进入解压后文件夹进行编译安装./configuremakemake install#下载并解压fastx 0.0.14：wget https://github.com/agordon/fastx_toolkit/releases/download/0.0.14/fastx_toolkit-0.0.14.tar.bz2tar –xjvf fastx_toolkit-0.0.14.tar.bz2#进入解压后文件夹进行编译安装./configuremakemake install#配置环境变量vi /etc/profile添加如下行export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH 5.安装bowtie2(旧流程）12345678#安装依赖包libtbb2apt-get install libtbb2#下载并解压bowtie2wget https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.3.2/bowtie2-2.3.2-linux-x86_64.zip/downloadunzip bowtie2-2.3.2-linux-x86_64.zip#配置环境变量vi /etc/profileexport PATH=$PATH://home/RNAseq_tool/bowtie2-2.3.2 6.安装Tophat2（旧流程）12345678910111213#下载并解压wget http://ccb.jhu.edu/software/tophat/downloads/tophat-2.1.1.Linux_x86_64.tar.gztar –xzvf tophat-2.1.1.Linux_x86_64.tar.gz#添加软连接cd /usr/local/binln –s /home/RNAseq_tool/tophat-2.1.1.Linux_x86_64/tophat2#测试tophat2#下载并解压测试数据wget http://ccb.jhu.edu/software/tophat/downloads/test_data.tar.gztar –xzvf test_data.tar.gz#测试：（实际使用时需要额外生成index文件）cd test_datatophat2 -r 20 test_ref reads_1.fq reads_2.fq 7.安装HISAT2（Tophat替代工具）1234567891011#下载源码并解压wget http://ccb.jhu.edu/software/hisat2/downloads/hisat2-2.0.0-beta-source.zipunzip hisat2-2.0.0-beta-source.zip#进入解压后目录并编译安装cd hisat2-2.0.0-beta/make#添加环境变量并使其立即生效export PATH=$PATH:/home/RNAseq_tool/hisat2-2.0.0-betasource ~/.bashrc#试运行hisat2 8.安装samtools12345678910111213#下载依赖库：libncurses5-dev, zlib1g-dev libbz2-dev liblzma-devapt-get install libncurses5-dev zlib1g-dev libbz2-dev liblzma-dev#下载samtools 1.5，bcftools 1.5，htslib 1.5：wget https://github.com/samtools/samtools/releases/download/1.5/samtools-1.5.tar.bz2wget https://github.com/samtools/bcftools/releases/download/1.5/bcftools-1.5.tar.bz2wget https://github.com/samtools/htslib/releases/download/1.5/htslib-1.5.tar.bz2#安装三个工具（分别进入各工具文件夹，进行编译安装，顺序：htslib&gt;bcftools&gt;samtools）./configuremakemake install#注：编译安装默认路径为/usr/local/bin，所以无需添加环境变量#测试安装samtools 9.安装RSeQC(用于对bam文件进行质控,项目主页：http://rseqc.sourceforge.net/）12# Python2.7环境下pip install RSeQC 其由许多功能脚本组成，具体可以看官网信息（http://rseqc.sourceforge.net/） 10.安装HTseq（项目主页：http://htseq.readthedocs.io/en/release_0.9.1/）1234567# 安装依赖sudo apt-get install build-essential python2.7-dev python-numpy python-matplotlib python-pysam python-htseq# Python2.7环境下pip install HTSeq#常用功能展示htseq-count -h 11.安装bedtools12345678#下载并解压wget https://github.com/arq5x/bedtools2/releases/download/v2.26.0/bedtools-2.26.0.tar.gztar –xzvf bedtools-2.26.0.tar.gz#进入解压后文件目录进行编译安装makemake install#测试安装bedtools --version 12.安装cufflinks（旧流程）1234567#下载并解压wget http://cole-trapnell-lab.github.io/cufflinks/assets/downloads/cufflinks-2.2.1.Linux_x86_64.tar.gztar –xzvf cufflinks-2.2.1.Linux_x86_64.tar.gz#将目录添加至环境变量中export PATH=$PATH:/home/RNAseq_tool/cufflinks-2.2.1.Linux_x86_64#测试安装cufflinks 13.安装stringtie（cufflinks替代文件，项目主页在此）12345678910#下载并解压wget http://ccb.jhu.edu/software/stringtie/dl/stringtie-1.3.3b.Linux_x86_64.tar.gztar -zxvf stringtie-1.3.3b.Linux_x86_64.tar.gz#添加目录至系统环境变量vim /etc/profile添加如下行export PATH=$PATH:/home/RNAseq_tool/stringtie-1.3.3b.Linux_x86_64#试运行，如果如下图]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vcf文件详解]]></title>
    <url>%2F2017%2F01%2F11%2Fvcf%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[vcf具有表头部分和正文部分，其中表头部分是对正文部分中出现的缩写的解释。 vcf的正文部分，必须要有的是前面8列，一般来说有10列，分别是：12345678910CHROMPOSIDREFALTQUALFILTER [来自于##FILTER]INFOFORMAT可能会有样本的名称 CHROM 和 POS：参考序列名和variant的位置；如果是INDEL的话，位置是INDEL的第一个碱基位置。 ID：variant的ID。比如在dbSNP中有该SNP的id，则会在此行给出；若没有，则用”.”表示其为一个novel variant。 REF 和 ALT：参考序列的碱基 和 Variant的碱基。 QUAL：Phred格式(Phred_scaled)的质量值，表 示在该位点存在variant的可能性；该值越高，则variant的可能性越大；计算方法：Phred值 = -10 * log (1-p)。 p为variant存在的概率; 通过计算公式可以看出值为10的表示错误概率为0.1，该位点为variant的概率为90%。 FILTER：使用上一个QUAL值来进行过滤的话，是不够的。GATK能使用其它的方法来进行过滤，过滤结果中通过则该值为”PASS”;若variant不可靠，则该项不为”PASS”或”.”。 INFO：这一行是variant的详细信息，内容很多，以下再具体详述。 FORMAT 和 TTG11B：这两行合起来提供了’TTG11B′这个sample的基因型的信息。’TTG11B′代表这该名称的样品，是由BAM文件中的@RG下的 SM 标签决定的。前面7列阐明该变异位点位于参考基因组的哪条染色体，哪个位置，是否被数据库给标记了ID(通常说的是dbSNP)，该位置的参考基因组是什么碱基，这个变异位点变异成了什么碱基。找到这个变异的软件给它的质量值是多少，是否合格。 第8列 INFO 比较复杂，包含信息最多，看起来是一列，但是里面可以根据字段拆分成多列，都是 “TAG=Value”的形式,并使用”;”分隔。其中很多的TAG含义在VCF文件的头部注释信息##INFO中已给出。 常见的TAG有： AC，AF 和，AN[A开头的多和等位基因有关]： AC(Allele Count) 表示该等位基因的数目； AF(Allele Frequency) 表示等位基因的频率； AN(Allele Number) 表示等位基因的总数目。 对于1个diploid sample[二倍体样本]而言： 基因型 0/1表示sample为杂合子，等位基因数为1(双倍体的sample在该位点只有1个等位基因发生了突变)，等位基因的频率为0.5(双倍体的sample在该位点只有50%的等位基因发生了突变)，总的等位基因为2； 基因型 1/1表示sample为纯合的，等位基因数为2，等位基因的频率为1，总的等位基因为2。 DP：reads覆盖度。是一些reads被过滤掉后的覆盖度。[注意，第八列和第九列都有DP，都表示该位点覆盖深度的信息，但是详细意义可能是不同的大家可以探究一下，在head里面就可以找到相应信息] Dels：进行SNP和INDEL calling的结果中，有该TAG并且值为0表示该位点为SNV，没有则为INDEL。[可以根据这个tag分离indel和snv] 第9列信息：位点的基因型，测序深度的描述，一般有两列内容，前者为格式，后者为格式对应的数据。 第九列包含标签有GT,DP,FT,GL,PL,GP等等，这些标签的含义可以在该vcf文件的表头里面找到。即vcf文件中以 ##FORMAT 开头的部分 GT： 样品的基因型（genotype）。两个数字中间用’/“分 开，这两个数字表示双倍体的sample的基因型。0表示样品中有ref的allele； 1 表示样品中variant的allele； 2表示有第二个variant的allele。 因此： 0/0表示sample中该位点为纯合的，和ref一致； 0/1 表示sample中该位点为杂合的，有ref和variant两个基因型； 1/1表示sample中该位点为纯合的，和variant一致。 AD 和 DP： AD(Allele Depth)为sample中每一种allele的reads覆盖度,在diploid中则是用逗号分割的两个值，前者对应ref基因型，后者对应variant基因型； DP（Depth）为sample中该位点的覆盖度(一些reads被过滤掉的覆盖度)。 GQ： 基因型的质量值(Genotype Quality)。Phred格式(Phred_scaled)的质量值，表示在该位点该基因型存在的可能性；该值越高，则Genotype的可能性越大；计算方法：Phred值 = -10 * log (1-p) p为基因型存在的概率。 PL 指定三种基因型的质量值。这三种指定的基因型为(0/0,0/1,1/1)，这三种基因型的概率总和为1。该值越大，表明为该种基因型的可能性越小。 Phred值 = -10 * log (p) p为基因型存在的概率。]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[bwa用法笔记]]></title>
    <url>%2F2017%2F01%2F09%2Fbwa%E7%94%A8%E6%B3%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[一.BWA简介bwa（全称Burrows-Wheeler Aligner），主要功能是将差异度较小的序列比对到一个较大的参考基因组上。其中提供了三种算法： 算法 应用场景 BWA-backtrack illumina测序结果（reads长度不超过100bp） BWA-SW 支持序列长度70bp-1Mbp，同时支持剪接性比对(split alignments) BWA-MEM 最常用，最新，最准确，支持序列长度70bp-1Mbp，表现比BWA-backtrack好 二.构建index官方文档说明：1bwa index [-p prefix] [-a algoType] &lt;in.db.fasta&gt; 其中需要的数据库序列为fasta格式。 选项介绍：1234567-p 输出数据库的前缀（默认和输入的文件名一致，输出的数据库在其输入文件所在的文件夹，并以该文件名为前缀）-a 表示构造BWT索引的算法。可用选项有: is 是默认的算法，虽然相对较快，但是需要较大的内存，当构建的数据库大于2GB的时候就不能正常工作了。 bwtsw 对于短的参考序列式不工作的，必须要大于等于10MB, 但能用于较大的基因组数据，比如人的全基因组。 三.数据比对数据比对大多使用MEM(maximal exact matches) 进行 seeding alignments，再使用 SW(affine-gap Smith-Waterman) 算法进行 seeds 的延伸。 BWA–MEM 算法执行局部比对和剪接性。可能会出现 query 序列的多个不同的部位出现各自的最优匹配，导致 reads 有多个最佳匹配位点。这对 long reads 的比对是比较重要的结果。但是却会和 Picard 的 markDuplicates 程序不兼容。 使用方法：12bwa mem [potions] ref.fa reads.fq [mates.fq]#mem 进行局部比对，因此，对于一条序列的不同区域可能会产生多种最优匹配结果， 这对于long reads 来说尤为重要。 有些软件如 Picard’s markDuplicates 跟 mem 的这种剪接性比对不兼容,在这种情况下，可以使用 –M 选项来将 shorter split hits 标记为次优。 常用选项：123456-t 线程数，默认为1。-M 将 shorter split hits 标记为次优，以兼容 Picard’s markDuplicates 软件。-p 若无此参数：输入文件只有1个，进行单端比对；若输入文件有2个，则作为paired reads进行比对。若加入此参数：则仅以第1个文件作为输入(输入的文件若有2个，则忽略之)，该文件必须是read1.fq和read2.fa进行reads交叉的数据。-R STR 完整的read group的头部，可以用 '\t' 作为分隔符， 在输出的SAM文件中被解释为制表符TAB. read group 的ID，会被添加到输出文件的每一个read的头部。-T INT 当比对的分值比 INT 小时，不输出该比对结果，这个参数只影响输出的结果，不影响比对的过程。-a 将所有的比对结果都输出，包括 single-end 和 unpaired paired-end的 reads，但是这些比对的结果会被标记为次优。 运行例子：123bwa mem ref.fa reads.fq &gt; mem-se.sambwa mem ref.fa read1.fq read2.fq &gt; mem-pe.sambwa mem -t 4 -M -R "\@RG\tID:&#123;library&#125;\tLB:&#123;library&#125;\tPL:Illumina\tPU:&#123;sample&#125;\tSM:&#123;sample&#125;\" ref.fa read1.fastq read2.fastq &gt; mem-pe.sam 2&gt; ./mem-pe.log 参考资料： BWA项目主页 BWA命令详解-寂寞先生]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[samtools及bcftools常用参数和使用文档]]></title>
    <url>%2F2016%2F12%2F20%2Fsamtools%E5%8F%8ABCFtools%E5%B8%B8%E7%94%A8%E5%8F%82%E6%95%B0%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[一、概述samtools的说明文档：http://samtools.sourceforge.net/samtools.shtmlsamtools是一个用于操作sam和bam文件的工具合集。在前期测序数据的处理中比较常用。其包含许多命令，以下是常用命令的介绍。 二、viewview命令的主要功能：将sam文件转换成bam文件；然后对bam文件进行各种操作，比如数据的排序(其他命令功能)和提取(这些操作是对bam文件进行的，因而当输入为sam文件的时候，不能进行该操作)；最后将排序或提取得到的数据输出为bam或sam格式。 bam文件优点：bam文件为二进制文件，占用的磁盘空间比sam文本文件小；利用bam二进制文件的运算速度快。View重要参数：12345678910111213141516171819Usage: samtools view [options] &lt;in.bam&gt;|&lt;in.sam&gt; [region1 [...]]#默认情况下不加 region，则是输出所有的 region.Options: -b output BAM #默认下输出是 SAM 格式文件，该参数设置输出 BAM 格式 -h print header for the SAM output #默认下输出的 sam 格式文件不带 header，该参数设定输出sam文件时带 header 信息 -H print header only (no alignments) -S input is SAM #默认下输入是 BAM 文件，若是输入是 SAM 文件，则最好加该参数，否则有时候会报错。 -u uncompressed BAM output (force -b) #该参数的使用需要有-b参数，能节约时间，但是需要更多磁盘空间。 -F INT filtering flag, 0 for unset [0] Skip alignments with bits present in INT [0] #数字4代表该序列没有比对到参考序列上 #数字8代表该序列的mate序列没有比对到参考序列上 -q INT #最低比对质量 [0] -l STR only output reads in library STR [null] 常用命令示例123456789101112131415#将sam文件转换成bam文件$ samtools view -bS abc.sam &gt; abc.bam$ samtools view -b -S abc.sam -o abc.bam#提取比对到参考序列上的比对结果$ samtools view -bF 4 abc.bam &gt; abc.F.bam#提取paired reads中两条reads都比对到参考序列上的比对结果，只需要把两个4+8的值12作为过滤参数即可$ samtools view -bF 12 abc.bam &gt; abc.F12.bam#提取没有比对到参考序列上的比对结果$ samtools view -bf 4 abc.bam &gt; abc.f.bam#根据fasta文件，将 header 加入到 sam 或 bam 文件中$ samtools view -T genome.fasta -h scaffold1.sam &gt; scaffold1.h.sam 三、sortsort命令主要功能：对bam文件进行排序123Usage: samtools sort [-n] [-m &lt;maxMem&gt;] &lt;in.bam&gt; &lt;out.prefix&gt; -m 参数默认下是 500,000,000 即500M（不支持K，M，G等缩写）以下数据进行处理。对于处理大数据时，如果内存够用，则设置较大值，以节约时间。-n 设定排序方式按short reads的ID排序。默认下是按序列在fasta文件中的顺序（即header）和序列从左往右的位点排序。 四、index注意：必须对bam文件进行默认情况下的排序后，才能进行index。否则会报错。 建立索引后将产生后缀为.bai的文件，用于快速的随机处理。很多情况下需要有bai文件的存在，特别是显示序列比对情况下。 123456Usage: samtools index &lt;in.bam&gt; [out.index]例子：#以下两种命令结果一样$ samtools index abc.sort.bam$ samtools index abc.sort.bam abc.sort.bam.bai 五、mpileup(重要，此工具用于call snp)mpileup用法：该命令用于生成bcf文件，再使用bcftools进行SNP和Indel的分析。 其用法和最简单的例子如下：123456Usage: samtools mpileup [-EBug] [-C capQcoef] [-r reg] [-f in.fa] [-l list] [-M capMapQ] [-Q minBaseQ] [-q minMapQ] in.bam [in2.bam [...]]$ samtools mpileup -f genome.fasta abc.bam &gt; abc.txt$ samtools mpileup -gSDf genome.fasta abc.bam &gt; abc.bcf$ samtools mpileup -guSDf genome.fasta abc.bam | \ bcftools view -cvNg - &gt; abc.vcf mpileup不使用-u或-g参数时，则不生成二进制的bcf文件，而生成一个文本文件(输出到标准输出)。该文本文件统计了参考序列中每个碱基位点的比对情况；该文件每一行代表了参考序列中某一个碱基位点的比对结果。比如：12345678910scaffold_1 2841 A 11 ,,,...,.... BHIGDGIJ?FFscaffold_1 2842 C 12 ,$,,...,....^I. CFGEGEGGCFF+scaffold_1 2843 G 11 ,,...,..... FDDDDCD?DD+scaffold_1 2844 G 11 ,,...,..... FA?AAAA&lt;AA+scaffold_1 2845 G 11 ,,...,..... F656666166*scaffold_1 2846 A 11 ,,...,..... (1.1111)11*scaffold_1 2847 A 11 ,,+9acggtgaag.+9ACGGTGAAT.+9ACGGTGAAG.+9ACGGTGAAG,+9acggtgaag.+9ACGGTGAAG.+9ACGGTGAAG.+9ACGGTGAAG.+9ACGGTGAAG.+9ACGGTGAAG %.+....-..)scaffold_1 2848 N 11 agGGGgGGGGG !!$!!!!!!!!scaffold_1 2849 A 11 c$,...,..... !0000000000scaffold_1 2850 A 10 ,...,..... 353333333 mpileup生成的结果包含6行：参考序列名；位置；参考碱基；比对上的reads数；比对情况；比对上的碱基的质量。其中第5列比较复杂,做如下解释：1234567891 ‘.’代表与参考序列正链匹配。2 ‘,’代表与参考序列负链匹配。3 ‘ATCGN’代表在正链上的不匹配。4 ‘atcgn’代表在负链上的不匹配。5 ‘*’代表模糊碱基6 ‘^’代表匹配的碱基是一个read的开始；’^’后面紧跟的ascii码减去33代表比对质量；这两个符号修饰的是后面的碱基，其后紧跟的碱基(.,ATCGatcgNn)代表该read的第一个碱基。7 ‘$’代表一个read的结束，该符号修饰的是其前面的碱基。8 正则式’+[0-9]+[ACGTNacgtn]+’代表在该位点后插入的碱基；比如上例中在scaffold_1的2847后插入了9个长度的碱基acggtgaag。表明此处极可能是indel。9 正则式’-[0-9]+[ACGTNacgtn]+’代表在该位点后缺失的碱基； 六、bcftoolsbcftools用法：用于处理vcf(variant call format)文件和bcf(binary call format)文件。前者为文本文件，后者为其二进制文件。最主要的命令是view命令来进行SNP和Indel calling。该命令的使用例子为： 1$ bcftools view -cvNg abc.bcf &gt; snp_indel.vcf 使用bcftools得到variant calling结果后。需要对结果再次进行过滤。主要依据比对结果中第8列信息。其中的 DP4 一行较为重要，它提供了4个数据：1 比对结果和正链一致的reads数、2 比对结果和负链一致的reads数、3 比对结果在正链的variant上的reads数、4 比对结果在负链的variant上的reads数。可以设定 （value3 + value4）大于某一阈值，才算是variant。比如：1$ perl -ne 'print $_ if /DP4=(\d+),(\d+),(\d+),(\d+)/ &amp;&amp; ($3+$4)&gt;=10 &amp;&amp; ($3+$4)/($1+$2+$3+$4)&gt;=0.8' snp_indel.vcf &gt; snp_indel.final.vcf]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git简单实用笔记]]></title>
    <url>%2F2016%2F09%2F27%2Fgit%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[git是什么git是一种版本控制系统，在多人协作项目中很有用处。在对某文档进行多次修改的时候，需要一个软件来记录进行的所有修改，而针对不同人的修改，应该有所标记，以便于随时查错，返回上一版本。git作为这样一种分布式版本控制工具，其可以快速便捷地适应这样的要求。 各个平台下git的安装方法都在github官方网站中有详细的介绍，因此这里不再赘述。 git的使用创建git版本库git版本库用于储存将要被修改的文件，创建方式非常简单，创建一个空目录，输入一行git命令即可。在git bash或者Linux环境下，可以使用以下代码创建一个git版本库。 123$ mkdir mygit$ cd mygit$ git init 这样一个名为mygit的版本库就创建好了。 查看被修改的git版本库在对git版本库中的内容进行修改后，怎样查看被修改内容呢？有两种方法可以查看：第一种是使用git status命令进行查看。这条命令可以显示git版本库中有哪些文件被修改了，是否被检查等等。 12# 查看git仓库现在的状态$ git status 第二种是使用git diff命令对修改的地方进行详细查看，具体使用方法为：123# 查看名为myfile的文件中具体的修改内容$ git diff myfilegit下如何提交修改 git下对版本库中的内容修改方式分为两步，首先使用add命令检查出版本库中的所有修改；其次，使用commit命令提交修改。 git下常用的add命令为： 12# 检查版本库中的所有修改内容$ git add . git下提交修改的命令： 1234# 使用默认值对版本库中的修改进行提交$ git commit# 使用自定义的commit内容进行修改内容提交$ git commit -m "commit message here" 如果使用默认值进行commit，那么系统会自动生成一个文档，里面详细记录了版本库中的文件被怎样修改。不过，此时这个文档中的所有行都是被注释过的，如果的确需要提交commit，那么就需要对这个文件进行一定的修改。由于默认情况下，git bash使用内置的vim打开文档，键入i就可以对文档进行修改。一般情况下，只需要去掉文档中的#即可。 git下对分支的操作git中使用以下命令进行分支的创建并将指针转向该分支（branch）123456789101112# 建立一个名为dev的分支并转向该分支上工作$ git checkout -b dev# 转移到已有的名为dev的分支上进行工作$ git checkout dev# 查看已有分支及自己所在的工作分支$ git branch# 将dev分支并到master（主）分支上，合并后即可删除dev分支$ git merge dev# 图形化查看分支的合并情况$ git log --graph --pretty=oneline --abbrev-commit# 删除dev分支$ git branch -d dev git分支管理策略实际开发中管理git的原则： master应该为最稳定的分支，应该仅用来发布新版本，平时调试和小功能的提交不应该使用master分支。 合并分支的时候应该尽量使用-no-ff模式，即“禁止使用快速合并分支”，这样可以看出曾经做过分支的合并，从而更好地了解项目进程。最后的话 这只是git的简单使用，由于本人并没有多人协作大项目的经历，因此例如brach之间的冲突、多人协作中需要注意的问题等并没有涉及，这里也就没有加上。当然了解git的更高级的用法也是很有必要的。这里推荐廖雪峰的git教程，言简意赅又非常生动形象。]]></content>
      <categories>
        <category>Tools</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[常见hexo博客命令用法及博客优化过程]]></title>
    <url>%2F2016%2F09%2F25%2F%E5%B8%B8%E8%A7%81hexo%E5%8D%9A%E5%AE%A2%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95%E5%8F%8A%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[常见hexo命令以下是常见的hexo命令，在搭建hexo博客中一定会用到。新建一篇博文，默认保存在本地博客目录下的/source/_post文件夹中,并形成一个以name命名的md文件。 1$ hexo n 'name' 更新博客（生成新的静态博客文件） 1$ hexo g 预览博客（让博客服务器运行在本地，一般地址为localhost:4000） 1$ hexo s 部署博客到github等使用命令： 1$ hexo d 关于各命令的详细用法，在hexo的官方使用文档中有详细的介绍，这里不再赘述。需要注意的是，在配置过程中，_config.yml文件里涉及的选项等需要在选项名冒号后加一个空格再输入项目的值。 为博客添加分类、“关于我”、标签页面等创建分类页面，并且在菜单中显示页面链接1.新建一个页面，命名为categories。命令如下： 1hexo new page categories 2.编辑刚新建的页面，将页面类型设置为categories，主题会自动为这个页面显示所有分类 1234title: 分类date: 20xx-xx-xx xx:xx:xxtype: "categories"--- 3.在主页菜单中添加链接。编辑主题文件夹中的_config.yml，将menu中的categories: /categories注释去掉即可，如下： 12345menu: home: / categories: /categories archives: /archives tags: /tags 创建”关于我”页面，并且在菜单中显示页面链接1.新建一个about页面 1hexo new page "about" 2.为菜单添加about链接，在主题的_config.yml文件中进行修改，将menu中的about前的注释去掉即可。 12345menu: home: / categories: /categories archives: /archives tags: /tags 创建标签云页面，并且在菜单中显示页面链接操作方法和以上添加“关于我”及分类页面的操作方式类似，也需要新建页面并且对主题文件夹中的_config.yml文件进行修改。不过，值得注意的是博客文章中添加分类的方式。博客文章中通过修改标题部分的文字来注明这篇博文的所属类别及标签。如： 12345678---title: 使用github结合hexo搭建静态个人博客date: 2016-9-17categories: Configurationtags:- github- hexo--- 不同的标签使用代码所示的方法进行分割，也可以使用另一种方法来表示： 1tags: [github, hexo] 为博客添加搜索引擎收录这里本人使用google搜索收录。首先在google console中添加一个站点，点击界面右上角的添加属性，在弹出窗口中输入博客网站，随后会提示验证网站所有权。采用备用方法：html标记后，在网站首页中添加元标签，点击确认即可进行验证。 此时点击google console，点击网站的标题就可以进入管理页。可以看到侧边栏有一系列菜单，选择抓取中的站点地图，接着选择右侧的添加/测试站点地图，将自己博客中的sitemap.xml文件提交即可完成。 一般添加到google收录后，需要一天才能通过google搜索到网站的相关信息。 为博客添加访问量显示功能由于Next主题中已经集成了多种显示访问量的工具，只需要在原文件中稍稍修改即可。这里本人使用的是不蒜子的网站访问工具。删除掉注释代码后，工具即可使用，如果出现不能使用的情况，将不蒜子官网中的js代码部分添加到主页代码中即可。 参考资料 1.Hexo优化｜如何向google提交sitemap2.Hexo使用攻略：（三）Hexo的配置和使用3.Hexo博客优化配置之–为自己博客添加搜索引擎网页收录]]></content>
      <categories>
        <category>Blog</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[github结合hexo搭建个人静态博客]]></title>
    <url>%2F2016%2F09%2F17%2Fgithub%E7%BB%93%E5%90%88hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一、github的下载及github pages的配置github在多平台下都可以安装，google搜索github，进入官网即可下载自己所需要的版本。各版本安装过程均较为简单，且官方手册叙述详细，在此不再赘述。 下面以windows平台为例介绍后续配置方法。 下载完成后，打开git终端，首先使用cd命令跳转到相应盘符建立一个新的工作目录，并将git部署在此目录下。12345#将目录换至工作目录cd /e#新建一个名为mygit的工作目录用户存储本地项目mkdir mygitcd mygit 接下来，检查本机ssh-key的设置，此设置是为了安全地连接本机和github服务器。如果没有设置过ssh-key，这里则需要生成新的ssh-key。1234cd ~/.ssh#如果提示没有相应的文件或文件夹，需要创建一个新的ssh-key#邮箱需要填写注册github时使用的邮箱ssh-keygen -t rsa -C "邮箱地址@yourmail.com" 接着需要输入加密串。一段自己可以记得住的密码即可，会要求重复输入。最后会有ssh-key输出成功的提示，另外在.ssh文件夹中也可以发现新生成了公钥和密钥文件。 下面要做的是将公钥上传到github中，完成github服务器和本机的联系。在~.ssh文件夹中找到id_rsa.pub，并将其复制到github个人主页中的SSH and GPG keys一项中。 上传完成后进行测试，尝试连接github。使用以下代码实现。1ssh -T git@github.com 会要求输入刚才生成ssh-key时需要的加密串，输入正确后验证成功。接下来要进行github pages的创建。在github中创建一个repository，需要注意的是如果要创建github pages,必须以域名格式对此repository进行命名，即形如×××.github.io的形式。 复制此项目的在github中的地址，将项目克隆至本机。（需要注意的是，在github上搭建博客需要对github的工作原理及使用方法有一定了解，如项目的创建，克隆等等，可以参考git简明指南进行了解） 12#实际操作时，以自己的项目地址为准git clone https://github.com/aaaa/aaaa.git 如此便完成了github的本地配置以及github pages的配置。 二、Hexo模板的使用事实上，可以用于在github上搭建博客的模板和语言有很多种，比如基于node.js的Hexo,还有基于Ruby的jelyll等。由于node.js在windows下的安装更为简单，本人使用了Hexo作为搭建博客的模板。 首先需要下载node.js,其同样支持多种平台，下载链接在此。 windows下的安装同样十分简单，运行exe文件后一路下一步即可。安装完成后，打开cmd，在其中输入npm,如果出现了关于其用法的介绍，则说明node.js安装成功且其安装路径已经加入了系统环境变量中。 接下来使用npm下载博客模板，首先需要在本地新建一个文件夹用来存储博客需要的文件，拟将此文件夹命名为blog。 切换至blog目录，安装Hexo模板，使用如下代码：12cd blognpm install hexo-cli -g 接着安装博客所需要的相关插件1234567891011121314npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --savenpm install moment-timezone --save 下载完成后，即可进行博客的配置和博文的撰写。关于Hexo的相关文档，可以到这个网站进行查看，其中详细地介绍了Hexo博客模板中各个参数的使用。 搭建博客使用以下代码：12345hexo init blogcd blognpm installhexo g #生成静态文件，默认在当前目录下生成一个叫做public的文件夹#关于hexo命令的更多用法及更多命令，可以在帮助文档中进行查看。 预览博客，使用以下代码实现1hexo s 在浏览器地址栏中输入http://localhost:4000即可预览博客。另外在命令行中也可以看到可能存在的报错信息用于调试。 三、更换博客主题在github中或者hexo的项目网站中找到自己喜欢的主题，然后将其在github中的项目复制到本地，进而修改blog中的_config.yml文件，将theme字段修改为目标主题名称。此处以next主题为例对博客主题进行修改。1git clone https://github.com/iissnan/hexo-theme-next.git themes/next 更换完毕后，可能需要删除博客中的数据库文件，重启server服务后即可查看更换主题后的博客内容。12hexo cleanhexo s 关于next主题的相关修改方法文档，可以通过这里来了解更多，作者将主题配置的问题在那里列举地非常详细。 参考资料： 1.HelloDog——使用GitHub和Hexo搭建免费静态Blog2.令狐葱——手把手教你使用Hexo + Github Pages搭建个人独立博客3.Hexo官方文档4.Next使用文档]]></content>
      <categories>
        <category>Blog</category>
      </categories>
  </entry>
</search>
